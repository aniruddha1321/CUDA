{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFFmHjTGaUkn",
        "outputId": "3a865bfd-4ed2-4378-ba84-6e3af0d9c348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing two.cu\n"
          ]
        }
      ],
      "source": [
        "%%writefile two.cu\n",
        "\n",
        "#include \"cuda_runtime.h\"\n",
        "#include \"device_launch_parameters.h\"\n",
        "#include <iostream>\n",
        "#include <numeric>\n",
        "#include <chrono>\n",
        "\n",
        "// REDUCTION 1 – Interleaved Addressing without branch divergence\n",
        "__global__ void reduce1(int *g_in_data, int *g_out_data){\n",
        "    extern __shared__ int sdata[];  // stored in the shared memory\n",
        "\n",
        "    // Each thread loading one element from global onto shared memory\n",
        "    unsigned int tid = threadIdx.x;\n",
        "    unsigned int i = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    sdata[tid] = g_in_data[i];\n",
        "    __syncthreads();\n",
        "\n",
        "    // Reduction method -- occurs in shared memory\n",
        "    for(unsigned int s = 1; s < blockDim.x; s *= 2){\n",
        "        // note the stride as s *= 2 : this causes the interleaving addressing\n",
        "        int index = 2 * s * tid;    // now we don't need a diverging branch from the if condition\n",
        "        if (index + s < blockDim.x)\n",
        "        {\n",
        "            sdata[index] += sdata[index + s];   // s is used to denote the offset that will be combined\n",
        "        }\n",
        "        __syncthreads();\n",
        "    }\n",
        "    if (tid == 0){\n",
        "        g_out_data[blockIdx.x] = sdata[0];\n",
        "    }\n",
        "}\n",
        "\n",
        "// I hope to use this main file for all of the reduction files\n",
        "int main(){\n",
        "    int n = 1 << 22; // Increase to about 4M elements\n",
        "    size_t bytes = n * sizeof(int);\n",
        "\n",
        "    // Host/CPU arrays\n",
        "    int *host_input_data = new int[n];\n",
        "    int *host_output_data = new int[(n + 255) / 256]; // to have sufficient size for output array\n",
        "\n",
        "    // Device/GPU arrays\n",
        "    int *dev_input_data, *dev_output_data;\n",
        "\n",
        "    // Init data\n",
        "    srand(42); // Fixed seed\n",
        "    for (int i = 0; i < n; i++){\n",
        "        host_input_data[i] = rand() % 100;\n",
        "    }\n",
        "\n",
        "    // Allocating memory on GPU for device arrays\n",
        "    cudaMalloc(&dev_input_data, bytes);\n",
        "    cudaMalloc(&dev_output_data, (n + 255) / 256 * sizeof(int));\n",
        "\n",
        "    // Copying our data onto the device (GPU)\n",
        "    cudaMemcpy(dev_input_data, host_input_data, bytes, cudaMemcpyHostToDevice);\n",
        "\n",
        "    int blockSize = 256; // number of threads per block\n",
        "\n",
        "    auto start = std::chrono::high_resolution_clock::now(); // start timer\n",
        "\n",
        "    // Launch Kernel and Synchronize threads\n",
        "    int num_blocks = (n + blockSize - 1) / blockSize;\n",
        "    cudaError_t err;\n",
        "    reduce1<<<num_blocks, blockSize, blockSize * sizeof(int)>>>(dev_input_data, dev_output_data);\n",
        "    err = cudaGetLastError();\n",
        "    if (err != cudaSuccess) {\n",
        "        std::cerr << \"CUDA error: \" << cudaGetErrorString(err) << std::endl;\n",
        "    }\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    auto stop = std::chrono::high_resolution_clock::now();\n",
        "    auto duration = std::chrono::duration_cast<std::chrono::microseconds>(stop - start).count() / 1000.0; // duration in milliseconds with three decimal points\n",
        "\n",
        "    // Copying data back to the host (CPU)\n",
        "    cudaMemcpy(host_output_data, dev_output_data, (n + 255) / 256 * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Final reduction on the host\n",
        "    int finalResult = host_output_data[0];\n",
        "    for (int i = 1; i < (n + 255) / 256; ++i) {\n",
        "        finalResult += host_output_data[i];\n",
        "    }\n",
        "\n",
        "    // CPU Summation for verification\n",
        "    int cpuResult = std::accumulate(host_input_data, host_input_data + n, 0);\n",
        "    if (cpuResult == finalResult) {\n",
        "        std::cout << \"\\033[32m\"; // Set text color to green\n",
        "        std::cout << \"Verification successful: GPU result matches CPU result.\\n\";\n",
        "        std::cout << \"GPU Result: \" << finalResult << \", CPU Result: \" << cpuResult << std::endl;\n",
        "    } else {\n",
        "        std::cout << \"\\033[31m\"; // Set text color to red\n",
        "        std::cout << \"Verification failed: GPU result (\" << finalResult << \") does not match CPU result (\" << cpuResult << \").\\n\";\n",
        "        std::cout << \"GPU Result: \" << finalResult << \", CPU Result: \" << cpuResult << std::endl;\n",
        "    }\n",
        "    std::cout << \"\\033[0m\"; // Reset text color to default\n",
        "\n",
        "    double bandwidth = (duration > 0) ? (bytes / duration / 1e6) : 0; // computed in GB/s, handling zero duration\n",
        "    std::cout << \"Reduced result: \" << finalResult << std::endl;\n",
        "    std::cout << \"Time elapsed: \" << duration << \" ms\" << std::endl;\n",
        "    std::cout << \"Effective bandwidth: \" << bandwidth << \" GB/s\" << std::endl;\n",
        "\n",
        "    // Freeing memory\n",
        "    cudaFree(dev_input_data);\n",
        "    cudaFree(dev_output_data);\n",
        "    delete[] host_input_data;\n",
        "    delete[] host_output_data;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc two.cu -o two -O3 -lineinfo"
      ],
      "metadata": {
        "id": "OzIYJ5E3nAeo"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -arch=sm_75 two.cu -o two -lineinfo"
      ],
      "metadata": {
        "id": "XwnlxmSiaY_0"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./two"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQtSj1Ycaimn",
        "outputId": "da7f0ebb-e830-46db-be7e-0bcd3649cda4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mVerification successful: GPU result matches CPU result.\n",
            "GPU Result: 207451054, CPU Result: 207451054\n",
            "\u001b[0mReduced result: 207451054\n",
            "Time elapsed: 0.646 ms\n",
            "Effective bandwidth: 25.9709 GB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nsys profile -o tets ./two"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stgeizD2bIPg",
        "outputId": "30d93afa-7874-4215-8f78-919735ee88f3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nsys: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nsys --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3esL4vahWlH",
        "outputId": "adee1bf0-082d-4e8c-bbe5-3aa945427070"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nsys: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvidia-pyindex"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVd-D3W7hjP2",
        "outputId": "cf715967-8744-4ec0-cc14-16029b2274e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nvidia-pyindex\n",
            "  Downloading nvidia-pyindex-1.0.9.tar.gz (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvidia-pyindex\n",
            "  Building wheel for nvidia-pyindex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvidia-pyindex: filename=nvidia_pyindex-1.0.9-py3-none-any.whl size=8419 sha256=e971c1109f20c9c68a196398c765a5400f117e1ca255213b60165cf3510c2ec7\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/d0/7d/b68b3665d16ee20355e65fb7ef48b7ca26533217d9f09924fe\n",
            "Successfully built nvidia-pyindex\n",
            "Installing collected packages: nvidia-pyindex\n",
            "Successfully installed nvidia-pyindex-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! set -x \\\n",
        "&& cd $(mktemp -d) \\\n",
        "&& wget https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda_12.1.0_530.30.02_linux.run \\\n",
        "&& sudo sh cuda_12.1.0_530.30.02_linux.run --silent --toolkit \\\n",
        "&& rm cuda_12.1.0_530.30.02_linux.run"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2i1D0nmDikxO",
        "outputId": "80659ebf-c53e-4e1a-e9d0-6d2998d30221"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "++ mktemp -d\n",
            "+ cd /tmp/tmp.GgSYCkDmBk\n",
            "+ wget https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda_12.1.0_530.30.02_linux.run\n",
            "--2025-06-05 10:05:38--  https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda_12.1.0_530.30.02_linux.run\n",
            "Resolving developer.download.nvidia.com (developer.download.nvidia.com)... 23.59.88.207, 23.59.88.195\n",
            "Connecting to developer.download.nvidia.com (developer.download.nvidia.com)|23.59.88.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4245586997 (4.0G) [application/octet-stream]\n",
            "Saving to: ‘cuda_12.1.0_530.30.02_linux.run’\n",
            "\n",
            "cuda_12.1.0_530.30. 100%[===================>]   3.95G   256MB/s    in 24s     \n",
            "\n",
            "2025-06-05 10:06:02 (170 MB/s) - ‘cuda_12.1.0_530.30.02_linux.run’ saved [4245586997/4245586997]\n",
            "\n",
            "+ sudo sh cuda_12.1.0_530.30.02_linux.run --silent --toolkit\n",
            "+ rm cuda_12.1.0_530.30.02_linux.run\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PATH'] = os.environ['PATH'] + ':/usr/local/cuda/bin/'"
      ],
      "metadata": {
        "id": "1C0U4inejDv2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ncu --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bxxenahkbZm",
        "outputId": "55351fa4-13c2-46e7-8b39-7d50720958c9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA (R) Nsight Compute Command Line Profiler\n",
            "Copyright (c) 2018-2024 NVIDIA Corporation\n",
            "Version 2024.2.1.0 (build 34372528) (public-release)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!./two"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQG-eqo6kuFB",
        "outputId": "5079e1c6-7f60-4137-fd56-66f8b62ce11f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mVerification successful: GPU result matches CPU result.\n",
            "GPU Result: 207451054, CPU Result: 207451054\n",
            "\u001b[0mReduced result: 207451054\n",
            "Time elapsed: 123.677 ms\n",
            "Effective bandwidth: 0.135653 GB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc two.cu -o two -O2 -lineinfo"
      ],
      "metadata": {
        "id": "OGsTLDZDnRoz"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./two"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgsUkOVRnh7k",
        "outputId": "c58d4df3-ad76-46fd-d022-907b57aeb2b9"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mVerification successful: GPU result matches CPU result.\n",
            "GPU Result: 207451054, CPU Result: 207451054\n",
            "\u001b[0mReduced result: 207451054\n",
            "Time elapsed: 0.786 ms\n",
            "Effective bandwidth: 21.3451 GB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc two.cu -o two -O1 -lineinfo"
      ],
      "metadata": {
        "id": "d5ghd8epnkwr"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./two"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdLuVU0Nn0nv",
        "outputId": "cca1edcd-c972-465c-f76e-3dc14c3cf12c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mVerification successful: GPU result matches CPU result.\n",
            "GPU Result: 207451054, CPU Result: 207451054\n",
            "\u001b[0mReduced result: 207451054\n",
            "Time elapsed: 0.724 ms\n",
            "Effective bandwidth: 23.173 GB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TG1s4IuCn29P"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}